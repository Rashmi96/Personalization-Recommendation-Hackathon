{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install langchain langchain-community langchain-core transformers\n",
    "%pip install sentence-transformers\n",
    "%pip install chromadb\n",
    "%pip install bitsandbytes accelerate\n",
    "%pip uninstall keras\n",
    "%pip install keras==2.11.0\n",
    "%pip install tf-keras\n",
    "%pip install --upgrade transformers\n",
    "%pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Generate Customer Demographics Data\n",
    "def generate_customer_demographics(num_customers=1000):\n",
    "    customer_data = []\n",
    "    for _ in range(num_customers):\n",
    "        customer = {\n",
    "            'customer_id': fake.uuid4(),\n",
    "            'name': fake.name(),\n",
    "            'age': random.randint(18, 70),\n",
    "            'gender': random.choice(['Male', 'Female']),\n",
    "            'marital_status': random.choice(['Single', 'Married', 'Divorced']),\n",
    "            'education': random.choice(['High School', 'Bachelor', 'Master', 'PhD']),\n",
    "            'occupation': fake.job(),\n",
    "            'salary': random.randint(20000, 150000),  # Yearly salary\n",
    "        }\n",
    "        customer_data.append(customer)\n",
    "    return pd.DataFrame(customer_data)\n",
    "\n",
    "# Generate Customer Financial Behavior Data\n",
    "def generate_financial_behavior(customer_ids, num_records=2000):\n",
    "    financial_data = []\n",
    "    for _ in range(num_records):\n",
    "        product_type = random.choice(['Personal Loan', 'Home Loan', 'Credit Card'])\n",
    "        loan_amount = random.randint(5000, 500000) if product_type != 'Credit Card' else random.randint(5000, 150000)\n",
    "        credit_limit = random.randint(1000, 150000) if product_type == 'Credit Card' else None\n",
    "        utilization = random.uniform(0.1, 1.0) if product_type == 'Credit Card' else None\n",
    "        max_dpd = random.choice([0, 15, 30, 60, 90, 120])\n",
    "        default_status = random.choice([True, False])\n",
    "\n",
    "        financial_behavior = {\n",
    "            'customer_id': random.choice(customer_ids),\n",
    "            'product_type': product_type,\n",
    "            'loan_amount': loan_amount,\n",
    "            'credit_limit': credit_limit,\n",
    "            'credit_utilization': utilization,\n",
    "            'emi_paid': random.randint(1, 24),\n",
    "            'tenure_months': random.randint(12, 60),\n",
    "            'max_dpd': max_dpd,\n",
    "            'default_status': default_status\n",
    "        }\n",
    "        financial_data.append(financial_behavior)\n",
    "    return pd.DataFrame(financial_data)\n",
    "\n",
    "# Generate Customer Enquiries Data (Last 3 months)\n",
    "def generate_customer_enquiries(customer_ids, num_records=500):\n",
    "    enquiries_data = []\n",
    "    for _ in range(num_records):\n",
    "        product_type = random.choice(['Personal Loan', 'Home Loan', 'Credit Card'])\n",
    "        enquiry_amount = random.randint(5000, 500000) if product_type != 'Credit Card' else random.randint(5000, 100000)\n",
    "        enquiry = {\n",
    "            'customer_id': random.choice(customer_ids),\n",
    "            'enquiry_date': fake.date_between(start_date='-90d', end_date='today'),\n",
    "            'product_type': product_type,\n",
    "            'enquiry_amount': enquiry_amount,\n",
    "            'status': random.choice(['Approved', 'Rejected'])\n",
    "        }\n",
    "        enquiries_data.append(enquiry)\n",
    "    return pd.DataFrame(enquiries_data)\n",
    "\n",
    "# Generate Customer Transaction Data (Past 6 months)\n",
    "def generate_customer_transactions(customer_ids, num_records=5000):\n",
    "    transactions_data = []\n",
    "    for _ in range(num_records):\n",
    "        transaction_date = fake.date_between(start_date='-180d', end_date='today')\n",
    "        transaction_amount = random.uniform(50, 10000)\n",
    "\n",
    "        # Transaction description with salary-related and hobby keywords\n",
    "        transaction_description = random.choice([\n",
    "            'Salary from XYZ Corp', 'Amazon Purchase', 'Grocery Store', 'Gym Membership',\n",
    "            'Netflix Subscription', 'Restaurant', 'Fuel Station', 'Travel Booking',\n",
    "            'SALARY - ABC Corp', 'SAL credited from DEF Ltd', 'Monthly Salary GHI Pvt Ltd',\n",
    "            'Rent Payment', 'Car Insurance', 'Mobile Phone Bill', 'Electricity Bill', 'Spotify Subscription',\n",
    "            'Uber Ride', 'Etsy Shopping', 'Concert Ticket', 'Books Purchase'\n",
    "        ])\n",
    "\n",
    "        # Salary detection\n",
    "        salary_keywords = ['Salary', 'SALARY', 'SAL', 'SAL credited', 'Monthly Salary']\n",
    "        is_salary = any(keyword in transaction_description.upper() for keyword in salary_keywords)\n",
    "\n",
    "        # Hobbies detection based on transaction descriptions\n",
    "        hobbies = None\n",
    "        if \"Amazon\" in transaction_description or \"Etsy\" in transaction_description:\n",
    "            hobbies = 'Shopping'\n",
    "        elif \"Netflix\" in transaction_description or \"Spotify\" in transaction_description:\n",
    "            hobbies = 'Entertainment'\n",
    "        elif \"Gym\" in transaction_description:\n",
    "            hobbies = 'Fitness'\n",
    "        elif \"Concert\" in transaction_description:\n",
    "            hobbies = 'Music'\n",
    "        elif \"Books\" in transaction_description:\n",
    "            hobbies = 'Reading'\n",
    "        elif \"Travel\" in transaction_description or \"Uber Ride\" in transaction_description:\n",
    "            hobbies = 'Travel'\n",
    "\n",
    "        transaction = {\n",
    "            'customer_id': random.choice(customer_ids),\n",
    "            'transaction_date': transaction_date,\n",
    "            'transaction_amount': transaction_amount,\n",
    "            'transaction_description': transaction_description,\n",
    "            'account_balance': random.uniform(500, 20000),\n",
    "            'is_salary': is_salary,\n",
    "            'hobby_detected': hobbies\n",
    "        }\n",
    "        transactions_data.append(transaction)\n",
    "\n",
    "    return pd.DataFrame(transactions_data)\n",
    "\n",
    "def generate_customer_sentiments(customer_ids, num_records=5000):\n",
    "    sentiments_data = []\n",
    "\n",
    "    sentiment_sources = ['Twitter', 'Facebook', 'Instagram', 'LinkedIn', 'Reddit', 'TrustPilot', 'Google Reviews', 'YouTube Comments', 'Quora', 'Forums']\n",
    "    sentiment_labels = ['Positive', 'Neutral', 'Negative']\n",
    "\n",
    "    product_keywords = [\n",
    "        'Credit Card', 'Loan', 'Mutual Fund', 'Stock', 'Insurance', 'Netflix', 'Spotify', 'Gym Membership', 'Mortgage', 'Savings Account', 'Investment Plan',\n",
    "        'Health Insurance', 'Car Loan', 'Home Loan', 'Travel Insurance', 'Mobile Phone Plan', 'Laptop', 'Smartwatch', 'Streaming Service', 'Online Course', 'Luxury Watch',\n",
    "        'Gaming Console', 'Electric Vehicle', 'Home Security System', 'Smart Home Device', 'E-book Subscription', 'Meal Delivery Service', 'Fitness Tracker', 'Digital Wallet'\n",
    "    ]\n",
    "\n",
    "    intent_categories = {\n",
    "        'Product Interest': ['Looking for suggestions', 'What should I buy?', 'Any recommendations?', 'Best choice for me?', 'Which one is better?', 'Need a new option'],\n",
    "        'Service Satisfaction': ['Excellent service', 'Great support', 'Fantastic experience', 'Highly recommend', 'Loved my experience', 'Poor service', 'Frustrated', 'Regret', 'Worst experience'],\n",
    "        'Technical Support': ['Not working', 'Facing issues', 'Bug found', 'App crashes', 'Error message', 'Glitchy experience', 'Feature broken'],\n",
    "        'Financial Concern': ['Unexpected charges', 'Hidden fees', 'Interest rates too high', 'Account frozen', 'Fraudulent transaction', 'Unauthorized deduction', 'Late fee issue', 'Credit score impact'],\n",
    "        'Investment Interest': ['Best savings account', 'High-interest deposit', 'Mutual fund recommendations', 'Stock investment tips', 'Retirement planning', 'Cryptocurrency advice', 'Is this a good investment?'],\n",
    "        'Loan & Credit Inquiry': ['Loan eligibility', 'Credit card approval', 'Best mortgage rates', 'Personal loan options', 'Debt consolidation', 'EMI calculation', 'Low-interest credit card'],\n",
    "        'Subscription Inquiry': ['Netflix subscription', 'Spotify plan', 'Gym membership', 'Service renewal', 'Want to upgrade', 'Cancel subscription'],\n",
    "        'Customer Support': ['Need assistance', 'Support not responding', 'How do I contact?', 'Live chat not available', 'Waiting for response'],\n",
    "        'Comparison': ['Better than', 'Worse than', 'Compared to', 'Alternative to', 'How does this compare?', 'Which is best?'],\n",
    "        'Refund Request': ['Want my money back', 'Need a refund', 'Did not like it', 'Return process', 'Refund issue', 'Money not credited']\n",
    "    }\n",
    "\n",
    "    for _ in range(num_records):\n",
    "        sentiment_source = random.choice(sentiment_sources)\n",
    "        sentiment_label = random.choice(sentiment_labels)\n",
    "        sentiment_score = {'Positive': random.uniform(0.6, 1.0), 'Neutral': random.uniform(0.4, 0.6), 'Negative': random.uniform(0.0, 0.4)}[sentiment_label]\n",
    "\n",
    "        # Assign product dynamically\n",
    "        product_mentioned = random.choice(product_keywords)\n",
    "\n",
    "        # Generate sentiment text including product\n",
    "        sentiment_text = f\"{random.choice(intent_categories['Product Interest'])} about {product_mentioned}\" if sentiment_label != 'Negative' else f\"{random.choice(intent_categories['Service Satisfaction'])} with {product_mentioned}\"\n",
    "\n",
    "        # Determine intent based on sentiment text\n",
    "        intent = next((key for key, values in intent_categories.items() if any(phrase in sentiment_text for phrase in values)), 'Product Interest')\n",
    "\n",
    "        sentiment_entry = {\n",
    "            'customer_id': random.choice(customer_ids),\n",
    "            'sentiment_date': fake.date_between(start_date='-180d', end_date='today'),\n",
    "            'sentiment_source': sentiment_source,\n",
    "            'sentiment_text': sentiment_text,\n",
    "            'sentiment_label': sentiment_label,\n",
    "            'sentiment_score': round(sentiment_score, 2),\n",
    "            'intent': intent,\n",
    "            'product_mentioned': product_mentioned\n",
    "        }\n",
    "        sentiments_data.append(sentiment_entry)\n",
    "\n",
    "    return pd.DataFrame(sentiments_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_customer_data(num_customers=5000, num_financial_records=15000, num_enquiries=4000, num_transactions=20000, num_sentiments=100):\n",
    "    \"\"\"Generates and aggregates customer data for personalization and recommendation.\"\"\"\n",
    "\n",
    "    # Generate Data\n",
    "    customers = generate_customer_demographics(num_customers)\n",
    "    financial_behavior = generate_financial_behavior(customers['customer_id'], num_records=num_financial_records)\n",
    "    enquiries = generate_customer_enquiries(customers['customer_id'], num_records=num_enquiries)\n",
    "    transactions = generate_customer_transactions(customers['customer_id'], num_records=num_transactions)\n",
    "    social_sentiments = generate_customer_sentiments(customers['customer_id'], num_records=num_sentiments)\n",
    "\n",
    "    # Financial Summary\n",
    "    financial_summary = financial_behavior.groupby('customer_id').agg({\n",
    "        'loan_amount': 'mean',\n",
    "        'credit_limit': 'mean',\n",
    "        'credit_utilization': 'mean',\n",
    "        'emi_paid': 'sum',\n",
    "        'tenure_months': 'mean',\n",
    "        'max_dpd': 'max',\n",
    "        'default_status': 'mean',\n",
    "        'product_type': lambda x: list(x.unique())  # Convert to list for readability\n",
    "    }).reset_index()\n",
    "\n",
    "    # Transaction Summary (Fixing the `is_salary` filter issue)\n",
    "    transaction_summary = transactions.groupby('customer_id').agg({\n",
    "        'transaction_amount': 'mean',\n",
    "        'account_balance': 'mean',\n",
    "        'is_salary': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Ensure 'is_salary' exists before filtering\n",
    "    if 'is_salary' in transactions.columns:\n",
    "        salary_transactions = transactions[transactions['is_salary'] == 1]\n",
    "        salary_summary = salary_transactions.groupby('customer_id')['transaction_amount'].sum().reset_index()\n",
    "        salary_summary.rename(columns={'transaction_amount': 'total_salary_received'}, inplace=True)\n",
    "        transaction_summary = pd.merge(transaction_summary, salary_summary, on='customer_id', how='left')\n",
    "\n",
    "    # Enquiries Summary (Fixing column name consistency)\n",
    "    enquiries_summary = enquiries.groupby('customer_id').agg({\n",
    "        'enquiry_amount': 'mean',\n",
    "        'product_type': lambda x: x.nunique(),\n",
    "        'customer_id': 'count'\n",
    "    }).rename(columns={\n",
    "        'customer_id': 'total_enquiries',\n",
    "        'product_type': 'unique_products_enquired'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Sentiment Summary\n",
    "    sentiment_summary = social_sentiments.groupby('customer_id').agg({\n",
    "        'sentiment_score': 'mean',\n",
    "        'intent': lambda x: x.mode()[0] if not x.mode().empty else 'General',\n",
    "        'sentiment_label': lambda x: x.value_counts().to_dict()\n",
    "    }).reset_index()\n",
    "\n",
    "    # Merge All Data\n",
    "    merged_data = pd.merge(customers, financial_summary, on='customer_id', how='left')\n",
    "    merged_data = pd.merge(merged_data, enquiries_summary, on='customer_id', how='left')\n",
    "    merged_data = pd.merge(merged_data, transaction_summary, on='customer_id', how='left')\n",
    "    # merged_data = pd.merge(merged_data, sentiment_summary, on='customer_id', how='left')\n",
    "\n",
    "    # Step 1: Explode the list in 'product_type' column\n",
    "    df_exploded = merged_data.explode('product_type')\n",
    "    # Step 2: One-hot encode the 'product_type' column\n",
    "    df_encoded = pd.get_dummies(df_exploded['product_type'])\n",
    "    merged_data = pd.concat([df_exploded, df_encoded], axis=1)\n",
    "    # Step 4: Group by the original index and aggregate to bring it back into one row per customer\n",
    "    df_final = merged_data.groupby(merged_data.index).sum()\n",
    "\n",
    "    # Define the aggregation function for each column\n",
    "    aggregation_functions = {\n",
    "    'customer_id': 'first',  # Keep first occurrence (assuming it's the same for the group)\n",
    "    'name': 'first',         # Keep the first name in each group\n",
    "    'age': 'mean',           # For age, you can take the average or median\n",
    "    'gender': 'first',       # Assuming gender is the same within each group, take the first\n",
    "    'marital_status': 'first', # Same for marital status\n",
    "    'education': 'first',    # Same for education\n",
    "    'occupation': 'first',   # Same for occupation\n",
    "    'salary': 'sum',         # Sum numerical values like salary\n",
    "    'loan_amount': 'sum',    # Sum numerical values like loan amount\n",
    "    'credit_limit': 'sum',   # Sum numerical values like credit limit\n",
    "    'credit_utilization': 'sum',\n",
    "    'emi_paid':'sum',\n",
    "    'tenure_months':'sum',\n",
    "    'max_dpd':'max',\n",
    "    'default_status':'max',\n",
    "    'enquiry_amount': 'sum',\n",
    "    'unique_products_enquired': 'sum',\n",
    "    'total_enquiries': 'sum',\n",
    "    'transaction_amount': 'sum',\n",
    "    'account_balance': 'sum',\n",
    "    'is_salary': 'mean',     # For boolean-like columns, you can take the mean (0 or 1)\n",
    "    'Credit Card': 'max',    # For categorical (binary) features, take max (0 or 1)\n",
    "    'Home Loan': 'max',\n",
    "    'Personal Loan': 'max',\n",
    "    }\n",
    "\n",
    "    # Group by and apply aggregation functions\n",
    "    df_final = merged_data.groupby(merged_data.index).agg(aggregation_functions)\n",
    "    df_final['content'] = df_final.apply(lambda row: f\"Based on the following customer data: {row.to_dict()}, suggest suitable products.\", axis=1)\n",
    "\n",
    "    # pd.set_option('display.max_colwidth', None)\n",
    "    # # Print the entire 'content' column\n",
    "    # print(df_final['content'].to_string())\n",
    "\n",
    "\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# Usage Example:\n",
    "df_final = generate_customer_data()\n",
    "print(df_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "#Prepare Document for langchain\n",
    "documents = []\n",
    "for _,row in df_final.iterrows():\n",
    "    documents.append(Document(page_content=row['content'], metadata={\"class\": row[\"age\"]}))\n",
    "\n",
    "hg_embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "persist_directory = '/content/sample_data/chroma_data'\n",
    "langchain_chroma = Chroma.from_documents(\n",
    "    documents= documents,\n",
    "    collection_name=\"recomendation_engine\",\n",
    "    embedding=hg_embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "def create_chroma_vector_store(df, persist_directory='/content/sample_data/chroma_data'):\n",
    "\n",
    "    # Prepare Documents for LangChain\n",
    "    documents = [Document(page_content=row['content'], metadata={\"class\": row[\"age\"]}) for _, row in df.iterrows()]\n",
    "\n",
    "    # Initialize Embeddings\n",
    "    hg_embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "    # Create Chroma Vector Store\n",
    "    langchain_chroma = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        collection_name=\"recommendation_engine\",\n",
    "        embedding=hg_embeddings,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "\n",
    "    return langchain_chroma\n",
    "\n",
    "# Usage Example:\n",
    "# langchain_chroma = create_chroma_vector_store(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch import cuda, bfloat16\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from time import time\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "import os\n",
    "\n",
    "model_id = 'HuggingFaceH4/zephyr-7b-beta'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type ='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code = True,\n",
    "    max_new_tokens =1024\n",
    "    )\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map ='auto',\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "query_pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    torch_dtype = torch.bfloat16,\n",
    "    max_length = 6000,\n",
    "    max_new_tokens = 500,\n",
    "    device_map = \"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def colorize_text(text):\n",
    "  for word, color in zip([\"Reasoning\",\"Question\",\"Answer\",\"Total time\"],[\"blue\",\"red\",\"green\",\"magneta\"]):\n",
    "    text = text.replace(f\"{word}:\",f\"\\n\\n**<font color='{color}'>{word}:</font>**\")\n",
    "  return text\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=query_pipeline)\n",
    "\n",
    "question = \"what is Recommendation Engine and How it used in Finance Domain?\"\n",
    "respone = llm(prompt=question)\n",
    "\n",
    "full_response = f\"Question: {question}\\n\\nAnswer: {respone}\"\n",
    "display(Markdown(colorize_text(full_response)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA # Corrected import statement\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms  import HuggingFaceHub # Corrected the typo in the package name\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\"\n",
    "\n",
    "template =\"\"\"\n",
    "Based on the following customer data, that I provide, suggest one suitable products.\"\n",
    "Customer Information: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=template, input_variables=[\"context\",\"question\"])\n",
    "\n",
    "retriver =langchain_chroma.as_retriever(search_kwargs={\"k\":1})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriver,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\":PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "question = df_final.iloc[2]\n",
    "question = question.drop('content')\n",
    "question_dict = question.to_dict()\n",
    "data_string = json.dumps(question_dict, indent=4)\n",
    "\n",
    "try:\n",
    "  result = qa_chain({\"query\": data_string})\n",
    "  print(result[\"result\"])\n",
    "except Exception as e:\n",
    "  print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
